{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szaveri99/LLM_Chatbot/blob/main/PdfQuery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBtk_tC8zmC1"
      },
      "source": [
        "## PDF Query Using Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rdAYZepFhJM"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install PyPDF2\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken\n",
        "!pip install streamlit\n",
        "!pip install pyngrok==4.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LFrISf2jrn4"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "import openai\n",
        "\n",
        "_*load_dotenv(find_dotenv())\n",
        "\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8fCmC-6Q3pP"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP1-3VjZdlf4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5VuMxSORSCg",
        "outputId": "7a45a89d-fd03-46ab-f0b1-fb39442884e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-04 08:39:34--  https://pgcag.files.wordpress.com/2010/01/48lawsofpower.pdf\n",
            "Resolving pgcag.files.wordpress.com (pgcag.files.wordpress.com)... 192.0.72.25, 192.0.72.24\n",
            "Connecting to pgcag.files.wordpress.com (pgcag.files.wordpress.com)|192.0.72.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 104926 (102K) [application/pdf]\n",
            "Saving to: â€˜48lawsofpower.pdfâ€™\n",
            "\n",
            "\r48lawsofpower.pdf     0%[                    ]       0  --.-KB/s               \r48lawsofpower.pdf   100%[===================>] 102.47K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-02-04 08:39:34 (29.8 MB/s) - â€˜48lawsofpower.pdfâ€™ saved [104926/104926]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://pgcag.files.wordpress.com/2010/01/48lawsofpower.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4uq8cwyRgEX"
      },
      "outputs": [],
      "source": [
        "# !mkdir docs\n",
        "# !mv 48lawsofpower.pdf docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FA1ZERdRLAM"
      },
      "outputs": [],
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('48lawsofpower.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9AeO9cDRqMj"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP6ap_PSRt7s"
      },
      "outputs": [],
      "source": [
        "# We need to split the text using Character Text Split such that it sshould not increase token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqy4vJhrSXUT"
      },
      "outputs": [],
      "source": [
        "# Download embeddings from OpenAI\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3igYiWjISjvS"
      },
      "outputs": [],
      "source": [
        "document_search = FAISS.from_texts(texts, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYl2PzKSSqg0",
        "outputId": "e9f61fcd-6534-4031-fa83-8e76077ee397"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "GQafhpOz4IsV",
        "outputId": "f4368135-6167-4ab5-d2de-56cc64eb5761"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" One example from history where an enemy was crushed totally is the case of Emperor Sung of China in 959 A.D. Despite facing numerous enemies and potential threats to his throne, Sung was able to turn all of his enemies into loyal friends by showing generosity and sparing their lives. This ultimately led to the enemies becoming grateful and loyal allies, effectively crushing their power and eliminating any future threat to Sung's rule.\""
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"Can you give me an example from history where the enemy was crushed totally from the book?\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "7sjc1Xh2SsTs",
        "outputId": "ae33804e-270d-4c3b-e2d6-6cfa8df13ff4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The point of making yourself less accessible is to create a sense of scarcity and increase your value in the eyes of others. By creating an aura of unpredictability and keeping others in a state of suspended terror, you can gain power and respect. This can be applied in various situations, such as seduction, love, and business. It also helps to protect your power and prevent others from taking you for granted.'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What's the point of making myself less accessible?\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "YNcQjsxoqb4u",
        "outputId": "da5ce6ec-ea8f-44cb-f361-dfc4b347cd24"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' From the context given, it appears that the story of Queen Elizabeth I is referenced in the chapter on \"Law 37: Create Compelling Spectacles.\" The chapter discusses how powerful figures like Elizabeth I used spectacles and public displays to enhance their image and maintain their power. The context mentions that Elizabeth I refused to marry or commit to any suitor, making herself ungraspable and thus increasing her power and desirability. She also maintained her independence and refused to be obligated to anyone, while still seeking promises from both sides of political conflicts to secure her position. The context also mentions that she used displays and ceremonies to showcase her power and control over England. This is just a brief overview of the story of Queen Elizabeth I as mentioned in this book, but it is not a comprehensive retelling of her life and accomplishments.'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"Can you tell me the story of Queen Elizabeth I from this 48 laws of power book?\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WAa3B2lTJaV",
        "outputId": "c59da6dd-bb59-4bb1-f3b6-a249456f90f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from typing_extensions import Concatenate\n",
        "from langchain.llms import OpenAI\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "import openai\n",
        "\n",
        "def pdf_read():\n",
        "  #_*load_dotenv(find_dotenv())\n",
        "  load_dotenv(find_dotenv())\n",
        "\n",
        "  openai.api_key = os.environ['OPENAI_API_KEY']\n",
        "\n",
        "  # provide the path of  pdf file/files.\n",
        "  pdfreader = PdfReader('48lawsofpower.pdf')\n",
        "  return pdfreader\n",
        "\n",
        "def text_gen():\n",
        "  # read text from pdf\n",
        "  pdfreader = pdf_read()\n",
        "  raw_text = ''\n",
        "  for i, page in enumerate(pdfreader.pages):\n",
        "      content = page.extract_text()\n",
        "      if content:\n",
        "          raw_text += content\n",
        "\n",
        "  # We need to split the text using Character Text Split such that it sshould not increase token size\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "      separator = \"\\n\",\n",
        "      chunk_size = 800,\n",
        "      chunk_overlap  = 200,\n",
        "      length_function = len,\n",
        "  )\n",
        "  texts = text_splitter.split_text(raw_text)\n",
        "  print(texts)\n",
        "  # Download embeddings from OpenAI\n",
        "  embeddings = OpenAIEmbeddings()\n",
        "\n",
        "  document_search = FAISS.from_texts(texts, embeddings)\n",
        "  chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")\n",
        "\n",
        "  return (document_search,chain)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import openai\n",
        "import streamlit as st\n",
        "import model\n",
        "\n",
        "def get_answer(question):\n",
        "    # Use the Question Answering pipeline to get the answer\n",
        "\n",
        "    document_search, chain = model.text_gen()\n",
        "    docs = document_search.similarity_search(question)\n",
        "    result = chain.run(input_documents=docs, question=question)\n",
        "\n",
        "    return result\n",
        "\n",
        "st.title(\"ðŸ’¬ Chatbot\")\n",
        "\n",
        "if \"prompt\" not in st.session_state:\n",
        "    st.session_state.prompt = \"\"\n",
        "\n",
        "def submit():\n",
        "    st.session_state.prompt = st.session_state.widget\n",
        "    st.session_state.widget = \"\"\n",
        "\n",
        "# Define the user's question using text_input\n",
        "st.text_input(\"Enter text here\", key=\"widget\", on_change=submit)\n",
        "\n",
        "prompt = st.session_state.prompt\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
        "\n",
        "for msg in st.session_state.messages:\n",
        "    st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
        "\n",
        "if prompt:\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    st.chat_message(\"user\").write(prompt)\n",
        "    st.text_input(\"Ask me a question\",key=\"input_clear\",value=\"\")\n",
        "    # Add your Q&A logic here\n",
        "    result = get_answer(prompt)\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": result})\n",
        "    st.chat_message(\"assistant\").write(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8gCdK75yJPG",
        "outputId": "2dd65051-eeea-400a-c789-6f227ec6ac52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDUFrv2UJn3e",
        "outputId": "2acd0461-0134-4479-9391-49ab516bf576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2bu2RZ5ZnmsqIy8nEiCz9RjuLk7_82NbmP7tUiYj9S1uWX3HQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5LdqkzFJ0iy",
        "outputId": "c0b74ef5-045b-4919-a091-8354157dd8dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125966\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "!streamlit run app2.py&>/dev/null&\n",
        "!pgrep streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QSqsEcXoJ7OF",
        "outputId": "8d111be2-3837-452f-bd71-6cdc21ee93e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://8939-35-186-163-228.ngrok-free.app'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 209
        }
      ],
      "source": [
        "public_url = ngrok.connect(port='8501')\n",
        "public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MpFrB4VQ81U",
        "outputId": "3589d076-7f62-405e-f59e-d6136a6fb116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.186.163.228:8502\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Exception ignored in: <module 'threading' from '/usr/lib/python3.10/threading.py'>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1547, in _shutdown\n",
            "    _main_thread._stop()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1028, in _stop\n",
            "    def _stop(self):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/web/bootstrap.py\", line 69, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/web/server/server.py\", line 399, in stop\n",
            "    self._runtime.stop()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/runtime.py\", line 311, in stop\n",
            "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 798, in call_soon_threadsafe\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 515, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n"
          ]
        }
      ],
      "source": [
        "!streamlit run /content/app2.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOvAg-K6PZCG",
        "outputId": "bcc62d3a-dbb8-450d-c1b3-69ab9b2e9649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n"
          ]
        }
      ],
      "source": [
        "# Install psutil\n",
        "!pip install psutil\n",
        "\n",
        "import psutil\n",
        "\n",
        "# Function to find and kill a process by port\n",
        "def kill_process_by_port(port):\n",
        "    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):\n",
        "        if 'python' in proc.info['name'].lower() and f\":{port}\" in proc.info['cmdline']:\n",
        "            print(f\"Killing process with PID {proc.info['pid']}\")\n",
        "            proc.terminate()\n",
        "\n",
        "# Kill process on port 8501\n",
        "kill_process_by_port(8501)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbMN89FsP8ZR"
      },
      "outputs": [],
      "source": [
        "!lsof -i :8501  # to check whteher the port is free or not"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}